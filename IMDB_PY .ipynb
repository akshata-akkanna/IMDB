{"cells":[{"cell_type":"code","source":["#Import Spark Session - Encompasses SparkContext & SQLContext \nfrom pyspark.sql import SparkSession\n#SQL functions\nfrom pyspark.sql import functions\n#Get the raw data ----> I have used Databricks Filestore to store my files\nsourcepath = \"dbfs:/FileStore/tables/tsvfile/title_basics.tsv\"\n#read the tsv using the spark read function and store it into the dataframe\nLoadingTheFile = spark.read.csv(sourcepath,sep = \"\\t\",header = True,inferSchema = True)\n#Fetching the past 100 years data by refering to the release date i.e Startyear\nFetchingTheYear = LoadingTheFile.where(LoadingTheFile[\"startYear\"] >= 1921)\n#Counting movie releases made each year in the past 100 years\nFinalDistribution = FetchingTheYear.groupBy('startYear').count().withColumnRenamed('count','NumberOfMovies')\n#displaying the result\ndisplay(FinalDistribution)\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82e0e446-bf3e-45fe-b155-946da9441d96"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["1953",9752],["1957",14225],["1987",39471],["1956",12772],["1936",3361],["2016",373091],["2020",336766],["2012",296372],["1958",15152],["1943",2208],["1972",29716],["1931",3291],["1926",3402],["1938",3401],["1988",39234],["2019",374915],["1932",3079],["2017",393406],["1977",28543],["2014",338252],["1971",29383],["1984",35448],["1941",2502],["1982",33590],["2013",318078],["2005",147040],["2000",89754],["1965",23137],["1962",16561],["1954",11699],["1930",3186],["1981",29891],["1940",2628],["1978",29655],["1974",29041],["1959",15584],["2002",102422],["2009",206954],["2018",395382],["1995",65496],["1964",19965],["1946",2557],["2006",163229],["1921",4228],["1927",3514],["1976",29253],["1942",2419],["1935",2906],["1947",2970],["1967",26319],["1968",25239],["1922",3601],["1924",3094],["2004",132628],["2011",266346],["1939",3030],["1989",42170],["1992",48917],["1961",17098],["1951",8791],["1966",24811],["2022",3901],["2008",195259],["1955",12848],["1999",87166],["1963",18804],["1994",58036],["2025",14],["1950",7330],["1997",73398],["1973",30533],["1925",3387],["2007",180926],["1996",68774],["1983",33849],["1923",3040],["1969",28547],["2023",297],["1980",30852],["1944",2046],["1960",16581],["1934",2979],["1937",3585],["2021",146309],["1948",3649],["1986",37046],["1952",9369],["2024",64],["1985",37119],["1929",3651],["1979",29378],["2015",354460],["1998",82233],["1993",53368],["1949",4966],["2001",98671],["2010",233872],["1990",45362],["1928",3491],["1991",47455],["2003",114881],["1945",2056],["2027",6],["1975",29491],["1970",28074],["1933",2919],["2026",9],["2028",3]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"startYear","type":"\"string\"","metadata":"{}"},{"name":"NumberOfMovies","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>startYear</th><th>NumberOfMovies</th></tr></thead><tbody><tr><td>1953</td><td>9752</td></tr><tr><td>1957</td><td>14225</td></tr><tr><td>1987</td><td>39471</td></tr><tr><td>1956</td><td>12772</td></tr><tr><td>1936</td><td>3361</td></tr><tr><td>2016</td><td>373091</td></tr><tr><td>2020</td><td>336766</td></tr><tr><td>2012</td><td>296372</td></tr><tr><td>1958</td><td>15152</td></tr><tr><td>1943</td><td>2208</td></tr><tr><td>1972</td><td>29716</td></tr><tr><td>1931</td><td>3291</td></tr><tr><td>1926</td><td>3402</td></tr><tr><td>1938</td><td>3401</td></tr><tr><td>1988</td><td>39234</td></tr><tr><td>2019</td><td>374915</td></tr><tr><td>1932</td><td>3079</td></tr><tr><td>2017</td><td>393406</td></tr><tr><td>1977</td><td>28543</td></tr><tr><td>2014</td><td>338252</td></tr><tr><td>1971</td><td>29383</td></tr><tr><td>1984</td><td>35448</td></tr><tr><td>1941</td><td>2502</td></tr><tr><td>1982</td><td>33590</td></tr><tr><td>2013</td><td>318078</td></tr><tr><td>2005</td><td>147040</td></tr><tr><td>2000</td><td>89754</td></tr><tr><td>1965</td><td>23137</td></tr><tr><td>1962</td><td>16561</td></tr><tr><td>1954</td><td>11699</td></tr><tr><td>1930</td><td>3186</td></tr><tr><td>1981</td><td>29891</td></tr><tr><td>1940</td><td>2628</td></tr><tr><td>1978</td><td>29655</td></tr><tr><td>1974</td><td>29041</td></tr><tr><td>1959</td><td>15584</td></tr><tr><td>2002</td><td>102422</td></tr><tr><td>2009</td><td>206954</td></tr><tr><td>2018</td><td>395382</td></tr><tr><td>1995</td><td>65496</td></tr><tr><td>1964</td><td>19965</td></tr><tr><td>1946</td><td>2557</td></tr><tr><td>2006</td><td>163229</td></tr><tr><td>1921</td><td>4228</td></tr><tr><td>1927</td><td>3514</td></tr><tr><td>1976</td><td>29253</td></tr><tr><td>1942</td><td>2419</td></tr><tr><td>1935</td><td>2906</td></tr><tr><td>1947</td><td>2970</td></tr><tr><td>1967</td><td>26319</td></tr><tr><td>1968</td><td>25239</td></tr><tr><td>1922</td><td>3601</td></tr><tr><td>1924</td><td>3094</td></tr><tr><td>2004</td><td>132628</td></tr><tr><td>2011</td><td>266346</td></tr><tr><td>1939</td><td>3030</td></tr><tr><td>1989</td><td>42170</td></tr><tr><td>1992</td><td>48917</td></tr><tr><td>1961</td><td>17098</td></tr><tr><td>1951</td><td>8791</td></tr><tr><td>1966</td><td>24811</td></tr><tr><td>2022</td><td>3901</td></tr><tr><td>2008</td><td>195259</td></tr><tr><td>1955</td><td>12848</td></tr><tr><td>1999</td><td>87166</td></tr><tr><td>1963</td><td>18804</td></tr><tr><td>1994</td><td>58036</td></tr><tr><td>2025</td><td>14</td></tr><tr><td>1950</td><td>7330</td></tr><tr><td>1997</td><td>73398</td></tr><tr><td>1973</td><td>30533</td></tr><tr><td>1925</td><td>3387</td></tr><tr><td>2007</td><td>180926</td></tr><tr><td>1996</td><td>68774</td></tr><tr><td>1983</td><td>33849</td></tr><tr><td>1923</td><td>3040</td></tr><tr><td>1969</td><td>28547</td></tr><tr><td>2023</td><td>297</td></tr><tr><td>1980</td><td>30852</td></tr><tr><td>1944</td><td>2046</td></tr><tr><td>1960</td><td>16581</td></tr><tr><td>1934</td><td>2979</td></tr><tr><td>1937</td><td>3585</td></tr><tr><td>2021</td><td>146309</td></tr><tr><td>1948</td><td>3649</td></tr><tr><td>1986</td><td>37046</td></tr><tr><td>1952</td><td>9369</td></tr><tr><td>2024</td><td>64</td></tr><tr><td>1985</td><td>37119</td></tr><tr><td>1929</td><td>3651</td></tr><tr><td>1979</td><td>29378</td></tr><tr><td>2015</td><td>354460</td></tr><tr><td>1998</td><td>82233</td></tr><tr><td>1993</td><td>53368</td></tr><tr><td>1949</td><td>4966</td></tr><tr><td>2001</td><td>98671</td></tr><tr><td>2010</td><td>233872</td></tr><tr><td>1990</td><td>45362</td></tr><tr><td>1928</td><td>3491</td></tr><tr><td>1991</td><td>47455</td></tr><tr><td>2003</td><td>114881</td></tr><tr><td>1945</td><td>2056</td></tr><tr><td>2027</td><td>6</td></tr><tr><td>1975</td><td>29491</td></tr><tr><td>1970</td><td>28074</td></tr><tr><td>1933</td><td>2919</td></tr><tr><td>2026</td><td>9</td></tr><tr><td>2028</td><td>3</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Import Spark Session - Encompasses SparkContext & SQLContext \nfrom pyspark.sql import SparkSession\n#SQL functions\nfrom pyspark.sql import functions\n#Get the raw data ----> I have used Databricks Filestore to store my files\nsourcepath_principle = \"dbfs:/FileStore/tables/title_principals.tsv\"\nsourcepath_Basics = \"dbfs:/FileStore/tables/name_basics.tsv\"\n\n#read the tsv using the spark read function and store it into the dataframe\nLoadingTheFile_principle = spark.read.csv(sourcepath_principle,sep = \"\\t\",header = True,inferSchema = True)\nLoadingTheFile_basic = spark.read.csv(sourcepath_Basics,sep = \"\\t\",header = True,inferSchema = True)\n\n#Get the required parameter and value from both title and name dataframe\nsel_LoadingTheFile_principle=LoadingTheFile_principle.select(fx.col(\"tconst\"),fx.col(\"nconst\"),fx.col(\"category\"))\nsel_LoadingTheFile_basic=LoadingTheFile_basic.select(fx.col(\"nconst\"),fx.col(\"primaryName\"))\n\n#join both the data frame using the nconst\njoinedF = sel_LoadingTheFile_principle.join(sel_LoadingTheFile_basic , [\"nconst\"])\n\n#get only actor and director data from the resltset\njoin_act_dir = joinedF.where((fx.col(\"category\") == fx.lit(\"actor\")) | (fx.col(\"category\") == fx.lit(\"director\"))) \n\n#fetching only actor data from the category \ndf_with_actor = join_act_dir.withColumn(\"Actor\",(fx.when(fx.col(\"category\") == fx.lit(\"actor\") , fx.col(\"category\")))).where(fx.col(\"Actor\").isNotNull()).withColumnRenamed(\"primaryName\",\"actorName\")\n\n#fetching only director data from the category\ndf_with_dir = join_act_dir.withColumn(\"Director\",(fx.when(fx.col(\"category\") == fx.lit(\"director\") , fx.col(\"category\")))).where(fx.col(\"Director\").isNotNull()).withColumnRenamed(\"primaryName\",\"directorName\")\n\n#joining all the dataframes using the tconst\njoinedADd = join_act_dir.join(df_with_actor,['tconst'] , 'left').join(df_with_dir,['tconst'] , 'left')\n\n#selecting the required parameters \nclub_act=joinedADd.where((fx.col(\"actorName\").isNotNull()) & (fx.col(\"directorName\").isNotNull())).select(fx.col(\"tconst\"),fx.col(\"actorName\"),fx.col(\"directorName\"))\n\n#fetching the count of collabration between actor and director using groupBy and aggregate function\nfinalResult = club_act.groupBy(fx.col(\"actorName\"),fx.col(\"directorName\")).agg(fx.count(\"directorName\").alias(\"count\"))\n\n#Order by high to low \nfinal =finalResult.orderBy(fx.col(\"count\").desc())\n\n#show top ten collabrations\nfinalSet = final.head(10)\ndisplay(finalSet)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"684af9f4-76d2-47f9-9390-36255909c2e9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Luis Eduardo Motoa","Luizi Agudelo",14449],["Luis Eduardo Motoa","Roberto Reyes",14449],["Luis Eduardo Motoa","Noé Salazar",14449],["Dilip Joshi","Harshad Joshi",14411],["Sebastian Hofmeyr","Gert van Niekerk",13263],["Sebastian Hofmeyr","Henry Mylne",13263],["Dilip Joshi","Dharmessh Mehta",12747],["Jef Desmedt","Frank Tulkens",10522],["Peter Hobbs","Gloria Monty",10011],["Ravi Kiran","Lakshmi Srinivas",9756]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"actorName","type":"\"string\"","metadata":"{}"},{"name":"directorName","type":"\"string\"","metadata":"{}"},{"name":"count","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>actorName</th><th>directorName</th><th>count</th></tr></thead><tbody><tr><td>Luis Eduardo Motoa</td><td>Luizi Agudelo</td><td>14449</td></tr><tr><td>Luis Eduardo Motoa</td><td>Roberto Reyes</td><td>14449</td></tr><tr><td>Luis Eduardo Motoa</td><td>Noé Salazar</td><td>14449</td></tr><tr><td>Dilip Joshi</td><td>Harshad Joshi</td><td>14411</td></tr><tr><td>Sebastian Hofmeyr</td><td>Gert van Niekerk</td><td>13263</td></tr><tr><td>Sebastian Hofmeyr</td><td>Henry Mylne</td><td>13263</td></tr><tr><td>Dilip Joshi</td><td>Dharmessh Mehta</td><td>12747</td></tr><tr><td>Jef Desmedt</td><td>Frank Tulkens</td><td>10522</td></tr><tr><td>Peter Hobbs</td><td>Gloria Monty</td><td>10011</td></tr><tr><td>Ravi Kiran</td><td>Lakshmi Srinivas</td><td>9756</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Import Spark Session - Encompasses SparkContext & SQLContext \nfrom pyspark.sql import SparkSession\n#SQL functions\nfrom pyspark.sql import *\n#Get the raw data ----> I have used Databricks Filestore to store my files\nsourcepath = \"dbfs:/FileStore/tables/tsvfile/title_basics.tsv\"\nsourcepath_Basics = \"dbfs:/FileStore/tables/name_basics.tsv\"\n\n#read the tsv using the spark read function and store it into the dataframe\ndf_title = spark.read.csv(sourcepath,sep = \"\\t\",header = True,inferSchema = True)\ndf_name = spark.read.csv(sourcepath_Basics,sep = \"\\t\",header = True,inferSchema = True)\n\n#Get the required parameter and value from both title and name dataframe\ndf_filtered_name = df_name.filter(df_name[\"primaryName\"].isin(['Omar Sy', 'Saoirse Ronan',  'Frances McDormand'])).select('primaryName','knownForTitles')\ndf_filtered_title = df_title.select('tconst','titleType','genres')\n\n#As the data in the KnowForTitle is in the form of array lets split the data using comma seperater and remane the column\nsplitTitles = df_filtered_name.withColumn(\"knownForTitles\", explode(split(col(\"knownForTitles\"), \",\"))).withColumnRenamed(\"knownForTitles\",\"tconst\")\n\n#Joining splited dataframe and title dataframe using tconst \njoin_both = df_filtered_title.join(splitTitles,[\"tconst\"])\n\n#As the genes data is in the array format split the data\ngenes = join_both.withColumn(\"genres\", explode(split(col(\"genres\"), \",\")))\n\n#Getting the count of each genres acted by repspective Actor\nfinalResulr = genes.groupBy((\"genres\"),(\"primaryName\")).agg(count(\"genres\").alias(\"NumberofGenres\"))\n\n#Displaying the final result\ndisplay(finalResulr)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad8c1a44-d5f3-4937-8f46-ac3a93f9bcbf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Drama","Frances McDormand",4],["Comedy","Frances McDormand",3],["Romance","Frances McDormand",1],["Fantasy","Saoirse Ronan",1],["Comedy","Omar Sy",1],["Drama","Saoirse Ronan",4],["Thriller","Saoirse Ronan",1],["Biography","Omar Sy",1],["Drama","Omar Sy",1],["Action","Omar Sy",3],["Mystery","Saoirse Ronan",1],["Sci-Fi","Omar Sy",3],["Adventure","Saoirse Ronan",1],["Romance","Saoirse Ronan",2],["Action","Saoirse Ronan",1],["Adventure","Omar Sy",3],["Crime","Frances McDormand",2],["Thriller","Frances McDormand",1],["Adventure","Frances McDormand",1]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"genres","type":"\"string\"","metadata":"{}"},{"name":"primaryName","type":"\"string\"","metadata":"{}"},{"name":"NumberofGenres","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>genres</th><th>primaryName</th><th>NumberofGenres</th></tr></thead><tbody><tr><td>Drama</td><td>Frances McDormand</td><td>4</td></tr><tr><td>Comedy</td><td>Frances McDormand</td><td>3</td></tr><tr><td>Romance</td><td>Frances McDormand</td><td>1</td></tr><tr><td>Fantasy</td><td>Saoirse Ronan</td><td>1</td></tr><tr><td>Comedy</td><td>Omar Sy</td><td>1</td></tr><tr><td>Drama</td><td>Saoirse Ronan</td><td>4</td></tr><tr><td>Thriller</td><td>Saoirse Ronan</td><td>1</td></tr><tr><td>Biography</td><td>Omar Sy</td><td>1</td></tr><tr><td>Drama</td><td>Omar Sy</td><td>1</td></tr><tr><td>Action</td><td>Omar Sy</td><td>3</td></tr><tr><td>Mystery</td><td>Saoirse Ronan</td><td>1</td></tr><tr><td>Sci-Fi</td><td>Omar Sy</td><td>3</td></tr><tr><td>Adventure</td><td>Saoirse Ronan</td><td>1</td></tr><tr><td>Romance</td><td>Saoirse Ronan</td><td>2</td></tr><tr><td>Action</td><td>Saoirse Ronan</td><td>1</td></tr><tr><td>Adventure</td><td>Omar Sy</td><td>3</td></tr><tr><td>Crime</td><td>Frances McDormand</td><td>2</td></tr><tr><td>Thriller</td><td>Frances McDormand</td><td>1</td></tr><tr><td>Adventure</td><td>Frances McDormand</td><td>1</td></tr></tbody></table></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"IMDB_PY","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":693279711091750}},"nbformat":4,"nbformat_minor":0}
